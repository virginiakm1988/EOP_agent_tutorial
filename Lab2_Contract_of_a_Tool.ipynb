{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: The Contract of a Tool — Schemas, Pydantic, and Function Calling\n",
        "\n",
        "**Series**: Agentic Engineering Crash Course  \n",
        "**Module**: 2 — Tool Definition & Pydantic (Defining the Interface)  \n",
        "**Prerequisites**: Lab 1 (or familiarity with prompt-based tool selection), Python 3.10+, OpenAI API key  \n",
        "\n",
        "---\n",
        "\n",
        "## How to use this tutorial in Google Colab\n",
        "\n",
        "1. Open [Google Colab](https://colab.research.google.com/) and create a new notebook.\n",
        "2. For each **markdown section** below: insert a **Text cell** and paste the section.\n",
        "3. For each **code block**: insert a **Code cell** and paste the code, then run.\n",
        "4. Run cells in order from top to bottom.\n",
        "\n",
        "**Suggested time**: 45–60 min.  \n",
        "**Experiments**: Baseline (required). Exploration: Experiments 1–3 required; Experiment 4 optional.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Learning Objectives\n",
        "\n",
        "By the end of this lab you will be able to:\n",
        "\n",
        "1. **Define** tools using Pydantic models with typed arguments and descriptions.\n",
        "2. **Use** the OpenAI function-calling API to let the model invoke tools via structured JSON.\n",
        "3. **Observe** how schema quality (description wording, argument types, enum constraints) affects both tool selection and argument accuracy.\n",
        "4. **Implement** validation and error handling for malformed tool calls.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Theoretical Why: Schemas as Contracts\n",
        "\n",
        "### Mechanism\n",
        "\n",
        "Function-calling models decode into a **constrained output space** defined by a JSON Schema. The schema acts as both a **grammar constraint** (valid JSON, required fields, types) and a **semantic guide** (descriptions tell the model when and how to use the tool).\n",
        "\n",
        "- **JSON Schema and Pydantic**: Pydantic models map directly to JSON Schema. The model's field types (`str`, `int`, `Literal[\"a\",\"b\"]`) become schema constraints; the API enforces that the model's raw output conforms before you parse it.\n",
        "- **Description engineering**: The tool's `description` field is a **prompt fragment**. Its wording changes the probability that the model selects this tool for a given user query. Clear, non-overlapping descriptions reduce misrouting.\n",
        "- **Argument schemas as type constraints**: `enum` (or `Literal`) fields, `min`/`max` for numbers, `pattern` for strings — all narrow the output space and reduce invalid or ambiguous arguments.\n",
        "\n",
        "### Maintenance connection\n",
        "\n",
        "Malformed tool calls (wrong type, missing required field, invalid enum value) are a top failure class in EOP agents. **Pydantic validators** catch these before they reach business logic, giving you structured `ValidationError` diagnostics instead of runtime crashes or silent misuse.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Setup\n",
        "\n",
        "**Dependencies**: Python 3.10+, `openai`, `pydantic`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Install dependencies\n",
        "!pip install -q openai pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c006555",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Imports and API key (OpenAI or NVIDIA NIM)\n",
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "from typing import Literal\n",
        "\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "\n",
        "use_nim = os.environ.get(\"USE_NIM\", \"\").lower() in (\"1\", \"true\", \"yes\") or \"NIM_API_KEY\" in os.environ\n",
        "if use_nim:\n",
        "    if \"NIM_API_KEY\" not in os.environ:\n",
        "        os.environ[\"NIM_API_KEY\"] = getpass(\"Enter your NVIDIA API key (NIM): \")\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "        api_key=os.environ[\"NIM_API_KEY\"],\n",
        "    )\n",
        "    MODEL = os.environ.get(\"NIM_MODEL\", \"nvidia/llama-3.3-nemotron-super-49b-v1.5\")\n",
        "else:\n",
        "    if \"OPENAI_API_KEY\" not in os.environ:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "    client = OpenAI()\n",
        "    MODEL = \"gpt-4o-mini\"\n",
        "print(f\"Using model: {MODEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Baseline Code: Pydantic Tools and OpenAI Function Calling\n",
        "\n",
        "We define **three tools** as Pydantic `BaseModel` subclasses, convert them to the OpenAI `tools` format, send a user query, and parse/validate the model's tool call with Pydantic.\n",
        "\n",
        "### 4.1 Define the tool models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Pydantic tool models\n",
        "\n",
        "class GetWeather(BaseModel):\n",
        "    \"\"\"Retrieve the current weather for a given city. Use when the user asks about weather, temperature, or forecast.\"\"\"\n",
        "    city: str = Field(description=\"The city name, e.g. New York, Tokyo.\")\n",
        "\n",
        "class SearchDocs(BaseModel):\n",
        "    \"\"\"Search internal documentation by keyword. Use when the user asks about policies, procedures, or technical references.\"\"\"\n",
        "    query: str = Field(description=\"Search query or keywords.\")\n",
        "    top_k: int = Field(default=5, description=\"Maximum number of results to return (default 5).\", ge=1, le=20)\n",
        "\n",
        "class CreateTicket(BaseModel):\n",
        "    \"\"\"Create a support ticket in the ticketing system. Use when the user wants to report an issue, request help, or escalate.\"\"\"\n",
        "    title: str = Field(description=\"Short title or summary of the ticket.\")\n",
        "    severity: Literal[\"low\", \"medium\", \"high\"] = Field(description=\"Severity level: low, medium, or high.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: The **docstring** of each model becomes the tool's `description` in the API. The **Field(description=...)** on each argument becomes the parameter description in the JSON Schema — both drive tool selection and argument quality.\n",
        "\n",
        "### 4.2 Convert Pydantic models to OpenAI tools format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Pydantic to OpenAI tools format\n",
        "\n",
        "def pydantic_to_openai_tool(model: type[BaseModel], name: str | None = None) -> dict:\n",
        "    \"\"\"Build an OpenAI tool definition from a Pydantic model.\"\"\"\n",
        "    name = name or model.__name__\n",
        "    schema = model.model_json_schema()\n",
        "    # OpenAI expects \"parameters\" to be a JSON Schema object (type, properties, required).\n",
        "    # Pydantic's schema may include \"title\"; we keep properties and required.\n",
        "    parameters = {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": schema.get(\"properties\", {}),\n",
        "        \"required\": schema.get(\"required\", []),\n",
        "    }\n",
        "    description = model.model_json_schema().get(\"description\") or (model.__doc__ or \"\")\n",
        "    return {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": name,\n",
        "            \"description\": description.strip(),\n",
        "            \"parameters\": parameters,\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "# Tool registry: name -> Pydantic model (for parsing)\n",
        "TOOL_MODELS = {\n",
        "    \"GetWeather\": GetWeather,\n",
        "    \"SearchDocs\": SearchDocs,\n",
        "    \"CreateTicket\": CreateTicket,\n",
        "}\n",
        "\n",
        "tools_openai = [pydantic_to_openai_tool(m, name) for name, m in TOOL_MODELS.items()]\n",
        "print(json.dumps(tools_openai[0], indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Call the API and parse tool_calls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Chat with tools and parse response\n",
        "\n",
        "def chat_with_tools(user_message: str, temperature: float = 0.0):\n",
        "    \"\"\"Send user message with tools; return assistant message and any tool calls.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        temperature=temperature,\n",
        "        messages=[{\"role\": \"user\", \"content\": user_message}],\n",
        "        tools=tools_openai,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=500,\n",
        "    )\n",
        "    msg = response.choices[0].message\n",
        "    return msg\n",
        "\n",
        "\n",
        "def parse_and_validate_tool_call(tool_call) -> dict:\n",
        "    \"\"\"\n",
        "    Given one item from message.tool_calls, parse arguments and validate with Pydantic.\n",
        "    Returns dict with: tool_name, parsed_args (Pydantic model instance or None), error (if validation failed).\n",
        "    \"\"\"\n",
        "    name = tool_call.function.name\n",
        "    raw_args = tool_call.function.arguments\n",
        "    model_class = TOOL_MODELS.get(name)\n",
        "    result = {\"tool_name\": name, \"parsed_args\": None, \"error\": None}\n",
        "    if not model_class:\n",
        "        result[\"error\"] = f\"Unknown tool: {name}\"\n",
        "        return result\n",
        "    try:\n",
        "        args_dict = json.loads(raw_args)\n",
        "        result[\"parsed_args\"] = model_class.model_validate(args_dict)\n",
        "    except json.JSONDecodeError as e:\n",
        "        result[\"error\"] = f\"Invalid JSON: {e}\"\n",
        "    except ValidationError as e:\n",
        "        result[\"error\"] = f\"ValidationError: {e}\"\n",
        "    return result\n",
        "\n",
        "\n",
        "# Baseline run\n",
        "msg = chat_with_tools(\"What's the weather in San Francisco?\")\n",
        "print(\"Assistant content:\", msg.content or \"(no text)\")\n",
        "if msg.tool_calls:\n",
        "    for tc in msg.tool_calls:\n",
        "        out = parse_and_validate_tool_call(tc)\n",
        "        print(\"Tool:\", out[\"tool_name\"])\n",
        "        print(\"Parsed args:\", out[\"parsed_args\"])\n",
        "        print(\"Error:\", out[\"error\"])\n",
        "else:\n",
        "    print(\"No tool calls.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected**: The model returns a tool call for `GetWeather` with `{\"city\": \"San Francisco\"}` (or similar). Parsed args are a `GetWeather` instance; error is None.  \n",
        "**Record**: Selected tool, parsed arguments, validation status. This is the **control** for the experiments below.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Exploration Lab: Schema Quality and Validation\n",
        "\n",
        "### Experiment 1: Description A/B test\n",
        "\n",
        "**Variable**: Swap the **descriptions** of two tools (e.g. give `GetWeather` the old `SearchDocs` description and vice versa).  \n",
        "**Expected**: The model selects the tool whose description now matches the query — proving descriptions are the primary selection signal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Experiment 1 — Description A/B\n",
        "\n",
        "# Swap descriptions between GetWeather and SearchDocs (no mutation of tools_openai)\n",
        "tools_swapped = [\n",
        "    {\"type\": \"function\", \"function\": {**tools_openai[0][\"function\"], \"description\": tools_openai[1][\"function\"][\"description\"]}},\n",
        "    {\"type\": \"function\", \"function\": {**tools_openai[1][\"function\"], \"description\": tools_openai[0][\"function\"][\"description\"]}},\n",
        "]\n",
        "\n",
        "# Query about weather — but GetWeather now has the \"search docs\" description\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    temperature=0.0,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in Paris?\"}],\n",
        "    tools=tools_swapped,\n",
        "    tool_choice=\"auto\",\n",
        "    max_tokens=100,\n",
        ")\n",
        "msg = resp.choices[0].message\n",
        "if msg.tool_calls:\n",
        "    for tc in msg.tool_calls:\n",
        "        print(\"Selected tool:\", tc.function.name)\n",
        "        print(\"Arguments:\", tc.function.arguments)\n",
        "else:\n",
        "    print(\"No tool calls; content:\", msg.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: With swapped descriptions, the model may choose the tool whose *description* matches \"weather\" (SearchDocs in this setup), not the one whose *name* is GetWeather.  \n",
        "**Record**: Which tool was selected? This shows that **descriptions are prompts** for tool selection.\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 2: Missing enum constraint\n",
        "\n",
        "**Variable**: Remove the `Literal` from the `severity` field (e.g. use plain `str`).  \n",
        "**Expected**: The model may output values like `\"critical\"` or `\"urgent\"` that would be invalid for the original enum. If we keep Literal and the model outputs an invalid value, Pydantic raises `ValidationError`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Experiment 2 — Missing enum (plain str severity)\n",
        "\n",
        "class CreateTicketNoEnum(BaseModel):\n",
        "    \"\"\"Create a support ticket. Use when the user wants to report an issue or escalate.\"\"\"\n",
        "    title: str = Field(description=\"Short title of the ticket.\")\n",
        "    severity: str = Field(description=\"Severity level.\")  # No Literal — model can say anything\n",
        "\n",
        "tool_no_enum = pydantic_to_openai_tool(CreateTicketNoEnum, \"CreateTicket\")\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    temperature=0.3,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"I need to create a critical bug ticket for login failures.\"}],\n",
        "    tools=[tool_no_enum],\n",
        "    tool_choice=\"auto\",\n",
        "    max_tokens=100,\n",
        ")\n",
        "msg = resp.choices[0].message\n",
        "if msg.tool_calls:\n",
        "    for tc in msg.tool_calls:\n",
        "        print(\"Arguments (raw):\", tc.function.arguments)\n",
        "        # Try parsing with the STRICT model (Literal[\"low\",\"medium\",\"high\"])\n",
        "        try:\n",
        "            args = json.loads(tc.function.arguments)\n",
        "            strict_parsed = CreateTicket.model_validate(args)\n",
        "            print(\"Strict parse OK:\", strict_parsed)\n",
        "        except ValidationError as e:\n",
        "            print(\"Strict parse ValidationError:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: The model may return `\"severity\": \"critical\"`. With the strict `CreateTicket` model (Literal), validation fails. Without the enum, invalid values reach your code unless you add a validator.  \n",
        "**Record**: Note the raw `severity` value and whether strict validation failed. **Implication**: Use enums (or constrained types) so Pydantic catches invalid values.\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 3: Ambiguous argument names\n",
        "\n",
        "**Variable**: Rename a clear parameter (e.g. `city`) to something generic like `input`.  \n",
        "**Expected**: Argument accuracy drops; the parameter name acts as an implicit prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Experiment 3 — Ambiguous argument name\n",
        "\n",
        "class GetWeatherGeneric(BaseModel):\n",
        "    \"\"\"Retrieve the current weather for a given city. Use when the user asks about weather.\"\"\"\n",
        "    input: str = Field(description=\"The city name.\")  # Generic name\n",
        "\n",
        "tool_generic = pydantic_to_openai_tool(GetWeatherGeneric, \"GetWeather\")\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    temperature=0.0,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in NYC and Boston?\"}],\n",
        "    tools=[tool_generic],\n",
        "    tool_choice=\"auto\",\n",
        "    max_tokens=100,\n",
        ")\n",
        "msg = resp.choices[0].message\n",
        "if msg.tool_calls:\n",
        "    for tc in msg.tool_calls:\n",
        "        print(\"Arguments:\", tc.function.arguments)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: With a generic name like `input`, the model may still do well for simple queries, but for \"NYC and Boston\" it may put both in one string, omit one, or format oddly. Clear names (`city`, `query`) improve consistency.  \n",
        "**Record**: Compare argument quality (e.g. single city vs two cities) to the baseline `GetWeather(city=...)`. **Implication**: Argument names are part of the contract; keep them specific and consistent.\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 4: Validation failure handling\n",
        "\n",
        "**Variable**: Intentionally pass **invalid** JSON or invalid types to Pydantic (e.g. wrong type, missing required field, invalid enum).  \n",
        "**Expected**: `ValidationError` provides structured diagnostics (which field, what went wrong).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell: Experiment 4 — ValidationError handling\n",
        "\n",
        "# Simulate malformed tool output (as if the model returned bad JSON)\n",
        "bad_payloads = [\n",
        "    '{\"city\": 123}',                    # wrong type for city\n",
        "    '{}',                              # missing required city\n",
        "    '{\"title\": \"Bug\", \"severity\": \"critical\"}',  # invalid enum for CreateTicket\n",
        "]\n",
        "\n",
        "for raw in bad_payloads:\n",
        "    print(\"Input:\", raw)\n",
        "    try:\n",
        "        data = json.loads(raw)\n",
        "        # Try validating as GetWeather (first two) or CreateTicket (third)\n",
        "        if \"city\" in data or \"title\" not in data:\n",
        "            GetWeather.model_validate(data)\n",
        "        else:\n",
        "            CreateTicket.model_validate(data)\n",
        "        print(\"  -> Valid\")\n",
        "    except ValidationError as e:\n",
        "        print(\"  -> ValidationError:\")\n",
        "        for err in e.errors():\n",
        "            print(\"     \", err)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"  -> JSONDecodeError:\", e)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: Pydantic reports field path, error type, and message. Use this to log and fix malformed tool calls in production.  \n",
        "**Record**: Note how each payload fails. **Implication**: Always validate tool arguments with Pydantic before calling business logic; surface ValidationError in logs or user-facing error messages.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Maintenance Connection: Debugging and Evolving Tool Schemas\n",
        "\n",
        "### Diagnostic checklist: \"Right tool, wrong arguments\"\n",
        "\n",
        "| Step | Check | Fix |\n",
        "|------|--------|-----|\n",
        "| 1 | **Parameter descriptions** | Make each argument's description explicit (e.g. \"City name, e.g. New York\"). |\n",
        "| 2 | **Enum / Literal** | Use Literal or Enum for fixed sets (severity, status) so invalid values are caught. |\n",
        "| 3 | **Argument names** | Prefer specific names (`city`, `query`) over generic (`input`, `value`). |\n",
        "| 4 | **Required vs optional** | Mark optional args with default; required list in schema must match. |\n",
        "| 5 | **ValidationError handling** | Log and (optionally) return a clear message to the user or agent loop. |\n",
        "\n",
        "### Versioning and regression tests\n",
        "\n",
        "- **Version tool schemas**: Include a schema version or tool name suffix when you change parameters (e.g. `CreateTicket_v2`).\n",
        "- **Regression tests**: Store example user queries and expected (tool, args) pairs; run after model or schema changes to detect drift.\n",
        "\n",
        "### Backward-compatible evolution\n",
        "\n",
        "- **Add optional fields** with defaults so old callers still validate.\n",
        "- **Deprecate tools** by keeping the old tool in the list with a description like \"Deprecated. Use NewTool instead.\" and routing internally to the new implementation until clients migrate.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Summary and Next Steps\n",
        "\n",
        "### Takeaways\n",
        "\n",
        "1. **Schemas are contracts**: JSON Schema + Pydantic define both what the model can output and how you validate it.\n",
        "2. **Descriptions are prompts**: Tool and parameter descriptions drive selection and argument quality; keep them clear and non-overlapping.\n",
        "3. **Validation is defense-in-depth**: Pydantic validators catch malformed tool calls and give structured errors before business logic runs.\n",
        "\n",
        "### What's next\n",
        "\n",
        "**Lab 3: The Persistent Agent** — Memory & State. We'll build an agent that maintains state across multi-turn interactions, observe context-window limits, and implement a summarization strategy.\n",
        "\n",
        "---\n",
        "\n",
        "*End of Lab 2. Proceed to Lab 3 when ready.*\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Lab2_Contract_of_a_Tool.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
