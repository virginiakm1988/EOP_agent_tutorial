{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Lab4_Graphs_Cycles_and_Recovery.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: Graphs, Cycles & Recovery — LangGraph and Flow Logic\n",
        "\n",
        "**Series**: Agentic Engineering Crash Course\n",
        "**Module**: 4 — LangGraph / Flow Logic (Handling Cycles and Error Recovery)\n",
        "**Prerequisites**: Labs 1–3 (prompt structure, Pydantic tools, multi-turn state), Python 3.10+, OpenAI API key\n",
        "\n",
        "---\n",
        "\n",
        "## What You Will Build (Plain English)\n",
        "\n",
        "Labs 1–3 built individual agent capabilities: picking a tool, validating arguments, remembering context. This lab puts them together into a **workflow** — a structured sequence of steps where the agent can retry on failure, take different paths depending on what happened, and escalate to a human when stuck.\n",
        "\n",
        "The workflow is represented as a **graph**: a diagram of boxes (actions) connected by arrows (transitions). This is not a neural network — it's just a flowchart you write in code.\n",
        "\n",
        "> **New library this lab — LangGraph and LangChain**:\n",
        ">\n",
        "> - **LangChain** (`langchain-openai`, `langchain-core`): A Python library that wraps LLM API calls in a consistent interface. Instead of calling `client.chat.completions.create(...)` directly, you call `llm.invoke(messages)`. Same result, less boilerplate.\n",
        "> - **LangGraph** (`langgraph`): A library built on top of LangChain that lets you define agent workflows as graphs (nodes + edges). Each node is a Python function; edges define which node runs next. It handles state passing between nodes automatically.\n",
        ">\n",
        "> **New Python pattern — `TypedDict`**: A way to define a dictionary with named, typed keys. Used here to define what data the graph passes between nodes (e.g. `AgentState` holds messages, retry count, and last tool result). Think of it as a structured container that flows through the graph.\n",
        "\n",
        "---\n",
        "\n",
        "## How to use this tutorial in Google Colab\n",
        "\n",
        "1. Open [Google Colab](https://colab.research.google.com/) and create a new notebook.\n",
        "2. For each **markdown section** below: insert a **Text cell** and paste the section.\n",
        "3. For each **code block**: insert a **Code cell** and paste the code, then run.\n",
        "4. Run cells in order from top to bottom.\n",
        "\n",
        "**Suggested time**: 60–75 min.  \n",
        "**Experiments**: Baseline (required). Exploration: Experiments 1–3 required; Experiments 4–5 optional.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Learning Objectives\n",
        "\n",
        "By the end of this lab you will be able to:\n",
        "\n",
        "1. **Model** an agent workflow as a directed graph with nodes (actions) and edges (transitions).\n",
        "2. **Build** a LangGraph workflow with conditional routing, cycles (retry loops), and terminal states.\n",
        "3. **Observe** how graph structure affects reliability: what happens when a node fails, when a cycle doesn't terminate, when fallback logic is missing.\n",
        "4. **Implement** error-recovery patterns: retry with backoff, fallback tools, and human-in-the-loop escalation.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Theoretical Why: Agents as Graphs\n",
        "\n",
        "### Mechanism\n",
        "\n",
        "An agentic workflow is a **state machine** or **directed graph**. Each **node** performs an action (LLM call, tool execution, validation). Each **edge** encodes a transition condition. The graph passes a **state object** through nodes; each node reads and writes to it.\n",
        "\n",
        "Concepts to keep in mind:\n",
        "\n",
        "- **DAG vs. cyclic graph**: Simple pipelines (e.g. retrieve → generate → respond) are **DAGs**. Agents that self-correct or retry require **cycles** (e.g. route → execute → on failure → route again).\n",
        "- **State as edge payload**: The state object (messages, tool results, retry count, etc.) flows along the edges; routing decisions are based on it.\n",
        "- **Conditional edges**: The next node depends on the output of the current node (e.g. \"if tool call failed, retry; if succeeded, proceed; if max retries exceeded, escalate\").\n",
        "- **Termination guarantees**: Cycles need **explicit exit conditions** (max iterations, success criteria) to avoid infinite loops.\n",
        "\n",
        "**Maintenance connection**: EOP agent failures often show up as **hung workflows** (infinite retry) or **silent failures** (no fallback path). Understanding the graph structure is essential for diagnosing these. When something goes wrong, trace the path through the graph and check exit conditions and fallbacks.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Setup\n",
        "\n",
        "**Dependencies**: Python 3.10+, `openai`, `langgraph`, `langchain-core`, `langchain-openai`.\n",
        "\n",
        "> **Why four packages?**\n",
        "> - `openai` — the base API client (same as Labs 1–3)\n",
        "> - `langchain-openai` — LangChain's wrapper for OpenAI (gives us `ChatOpenAI`)\n",
        "> - `langchain-core` — shared data types used across LangChain (e.g. `AIMessage`, `HumanMessage`)\n",
        "> - `langgraph` — the graph engine that runs our agent workflow\n",
        ">\n",
        "> You only need to install these once. If you're in Colab, run the install cell first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Install dependencies\n",
        "!pip install -q openai langgraph langchain-core langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Imports and API key (OpenAI or NVIDIA NIM)\n",
        "import os\n",
        "import random\n",
        "from getpass import getpass\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "use_nim = os.environ.get(\"USE_NIM\", \"\").lower() in (\"1\", \"true\", \"yes\") or \"NIM_API_KEY\" in os.environ\n",
        "if use_nim:\n",
        "    if \"NIM_API_KEY\" not in os.environ:\n",
        "        os.environ[\"NIM_API_KEY\"] = getpass(\"Enter your NVIDIA API key (NIM): \")\n",
        "    MODEL = os.environ.get(\"NIM_MODEL\", \"nvidia/llama-3.3-nemotron-super-49b-v1.5\")\n",
        "    llm = ChatOpenAI(\n",
        "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "        api_key=os.environ[\"NIM_API_KEY\"],\n",
        "        model=MODEL,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "else:\n",
        "    if \"OPENAI_API_KEY\" not in os.environ:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "    MODEL = \"gpt-4o-mini\"\n",
        "    llm = ChatOpenAI(model=MODEL, temperature=0.0)\n",
        "print(f\"Using model: {MODEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Baseline Code: Three-Node Graph (Route → Execute → Respond)\n",
        "\n",
        "### 為什麼用圖來做 Agent（Why Use a Graph for the Agent?）\n",
        "\n",
        "Before writing code, it helps to see *why* we model the agent as a graph:\n",
        "\n",
        "- **Maintainability**: The flow is explicit. You can read the graph (nodes + edges) and see exactly where routing, execution, and response happen. No hidden state machines buried in conditionals.\n",
        "- **Debugging**: When something goes wrong, you trace the path: which node ran, which edge was taken, what the state was. Failures map to specific nodes or edges (e.g. \"execute failed\" or \"retry loop never exited\").\n",
        "- **Retry and fallback**: Cycles (e.g. route → execute → on failure → back to route) and alternate paths (e.g. fallback node when retries are exhausted) are natural in a graph. You add edges and conditions instead of ad-hoc loops.\n",
        "- **Visualization**: Tools like LangGraph can draw the graph so the whole workflow is visible at a glance.\n",
        "\n",
        "A minimal agent flow looks like this:\n",
        "\n",
        "```mermaid\n",
        "flowchart LR\n",
        "  Start((Start)) --> route[route]\n",
        "  route --> execute[execute]\n",
        "  execute --> respond[respond]\n",
        "  respond --> End((END))\n",
        "```\n",
        "\n",
        "We define a minimal graph:\n",
        "\n",
        "1. **route** — LLM decides which tool to call (or to respond).\n",
        "2. **execute** — Simulate tool execution (may succeed or fail).\n",
        "3. **respond** — Format the result for the user.\n",
        "\n",
        "Edges: `route → execute → respond → END`. State holds messages and the last tool result.\n",
        "\n",
        "### 4.1 State and tools\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: State and tool definitions\n",
        "\n",
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    last_tool_result: str\n",
        "    retry_count: int\n",
        "\n",
        "def tool_get_weather(query: str) -> str:\n",
        "    \"\"\"Get the current weather. Use when the user asks about weather.\"\"\"\n",
        "    return \"Sunny, 72°F\"\n",
        "\n",
        "def tool_search_docs(query: str) -> str:\n",
        "    \"\"\"Search documentation. Use when the user asks about docs or policies.\"\"\"\n",
        "    return \"Found 3 relevant articles.\"\n",
        "\n",
        "# Bind tools to the LLM\n",
        "tools = [tool_get_weather, tool_search_docs]\n",
        "llm_with_tools = llm.bind_tools(tools)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Nodes and graph (no cycle yet)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Baseline graph — route → execute → respond\n",
        "\n",
        "def route_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"LLM decides: call a tool or answer directly.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response], \"last_tool_result\": state.get(\"last_tool_result\", \"\"), \"retry_count\": state.get(\"retry_count\", 0)}\n",
        "\n",
        "def execute_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Execute the last tool call from the assistant message. Always succeeds in baseline.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    if not getattr(last_msg, \"tool_calls\", None):\n",
        "        return {**state, \"last_tool_result\": \"No tool call.\"}\n",
        "    tool_node = ToolNode(tools)\n",
        "    result = tool_node.invoke(state)\n",
        "    # Get the last tool message content as string\n",
        "    new_msgs = result[\"messages\"]\n",
        "    last_tool_msg = new_msgs[-1] if new_msgs else None\n",
        "    tool_result_str = last_tool_msg.content if last_tool_msg and hasattr(last_tool_msg, \"content\") else str(new_msgs)\n",
        "    return {\"messages\": new_msgs, \"last_tool_result\": tool_result_str, \"retry_count\": state.get(\"retry_count\", 0)}\n",
        "\n",
        "def respond_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Format final response for the user.\"\"\"\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response], \"last_tool_result\": state.get(\"last_tool_result\", \"\"), \"retry_count\": state.get(\"retry_count\", 0)}\n",
        "\n",
        "# Build graph\n",
        "graph_baseline = StateGraph(AgentState)\n",
        "graph_baseline.add_node(\"route\", route_node)\n",
        "graph_baseline.add_node(\"execute\", execute_node)\n",
        "graph_baseline.add_node(\"respond\", respond_node)\n",
        "graph_baseline.set_entry_point(\"route\")\n",
        "graph_baseline.add_edge(\"route\", \"execute\")\n",
        "graph_baseline.add_edge(\"execute\", \"respond\")\n",
        "graph_baseline.add_edge(\"respond\", END)\n",
        "\n",
        "app_baseline = graph_baseline.compile()\n",
        "\n",
        "# Run\n",
        "initial = {\"messages\": [(\"user\", \"What's the weather today?\")], \"last_tool_result\": \"\", \"retry_count\": 0}\n",
        "result = app_baseline.invoke(initial)\n",
        "print(\"Final message:\", result[\"messages\"][-1].content if result[\"messages\"] else \"—\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected**: The graph runs route → execute → respond; the agent calls the weather tool and returns a short answer.  \n",
        "**Record**: Final message content and that the path is linear.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Exploration Lab: Failures, Retries, Fallback, and Human-in-the-Loop\n",
        "\n",
        "**Experiment 1** is required to see failure without retry. **Experiments 2–5** are optional (選做) for retry cycles, fallback, conditional routing, and human-in-the-loop.\n",
        "\n",
        "### Experiment 1: Tool execution failure (no retry) — **Required**\n",
        "\n",
        "**Variable**: Make `execute` fail randomly (e.g. 50% of the time).  \n",
        "**Hypothesis**: Without retry logic, about half of runs produce errors or incomplete responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Experiment 1 — Execute fails 50%\n",
        "\n",
        "def execute_node_flaky(state: AgentState) -> AgentState:\n",
        "    \"\"\"Execute tool, but fail 50% of the time.\"\"\"\n",
        "    if random.random() < 0.5:\n",
        "        return {\n",
        "            **state,\n",
        "            \"last_tool_result\": \"ERROR: Tool execution failed (simulated).\",\n",
        "            \"messages\": state[\"messages\"]\n",
        "            + [type(state[\"messages\"][0])(content=\"ERROR: Tool execution failed.\", role=\"tool\")],\n",
        "        }\n",
        "    return execute_node(state)\n",
        "\n",
        "graph_flaky = StateGraph(AgentState)\n",
        "graph_flaky.add_node(\"route\", route_node)\n",
        "graph_flaky.add_node(\"execute\", execute_node_flaky)\n",
        "graph_flaky.add_node(\"respond\", respond_node)\n",
        "graph_flaky.set_entry_point(\"route\")\n",
        "graph_flaky.add_edge(\"route\", \"execute\")\n",
        "graph_flaky.add_edge(\"execute\", \"respond\")\n",
        "graph_flaky.add_edge(\"respond\", END)\n",
        "app_flaky = graph_flaky.compile()\n",
        "\n",
        "for run in range(4):\n",
        "    r = app_flaky.invoke({\"messages\": [(\"user\", \"What's the weather?\")], \"last_tool_result\": \"\", \"retry_count\": 0})\n",
        "    last = r[\"messages\"][-1].content if r[\"messages\"] else \"\"\n",
        "    print(f\"Run {run+1}: {last[:80]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: Some runs succeed, some reflect the error. **Record**: Proportion of runs that showed an error. **Implication**: Production graphs need retry or fallback when tools fail.\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 2: Retry cycle with max_retries — **Optional (選做)**\n",
        "\n",
        "**Variable**: Add a cycle: `route → execute → (if fail and retries < 3 → route else → respond)`.  \n",
        "**Hypothesis**: Transient failures are recovered; once max retries are used, we proceed to respond (or fallback).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Experiment 2 — Retry cycle (max 3)\n",
        "\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "def route_node_retry(state: AgentState) -> AgentState:\n",
        "    retry_count = state.get(\"retry_count\", 0)\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response], \"last_tool_result\": state.get(\"last_tool_result\", \"\"), \"retry_count\": retry_count}\n",
        "\n",
        "def execute_node_with_fail(state: AgentState) -> AgentState:\n",
        "    if random.random() < 0.6:  # Fail 60%\n",
        "        return {\n",
        "            **state,\n",
        "            \"last_tool_result\": \"ERROR\",\n",
        "            \"retry_count\": state.get(\"retry_count\", 0) + 1,\n",
        "        }\n",
        "    return execute_node(state)\n",
        "\n",
        "def should_retry(state: AgentState) -> str:\n",
        "    if state.get(\"last_tool_result\") == \"ERROR\" and state.get(\"retry_count\", 0) < MAX_RETRIES:\n",
        "        return \"route\"\n",
        "    return \"respond\"\n",
        "\n",
        "graph_retry = StateGraph(AgentState)\n",
        "graph_retry.add_node(\"route\", route_node_retry)\n",
        "graph_retry.add_node(\"execute\", execute_node_with_fail)\n",
        "graph_retry.add_node(\"respond\", respond_node)\n",
        "graph_retry.set_entry_point(\"route\")\n",
        "graph_retry.add_edge(\"route\", \"execute\")\n",
        "graph_retry.add_conditional_edges(\"execute\", should_retry, {\"route\": \"route\", \"respond\": \"respond\"})\n",
        "graph_retry.add_edge(\"respond\", END)\n",
        "app_retry = graph_retry.compile()\n",
        "\n",
        "# Run a few times and observe retry count\n",
        "for run in range(3):\n",
        "    r = app_retry.invoke({\"messages\": [(\"user\", \"Weather?\")], \"last_tool_result\": \"\", \"retry_count\": 0})\n",
        "    print(f\"Run {run+1}: retry_count={r.get('retry_count', 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: When execute fails, the graph loops back to route; when it succeeds or retries are exhausted, it goes to respond. **Record**: Distribution of retry counts over several runs.\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 3: Fallback path when retries exhausted — **Optional (選做)**\n",
        "\n",
        "**Variable**: Add a **fallback** node that returns a canned message when retries are exhausted.  \n",
        "**Hypothesis**: The agent degrades gracefully instead of returning an error to the user.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Experiment 3 — Fallback node\n",
        "\n",
        "def fallback_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Canned response when we give up after retries.\"\"\"\n",
        "    from langchain_core.messages import HumanMessage, AIMessage\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=\"I couldn't complete that request after several tries. Please try again later or contact support.\")],\n",
        "        \"last_tool_result\": state.get(\"last_tool_result\", \"\"),\n",
        "        \"retry_count\": state.get(\"retry_count\", 0),\n",
        "    }\n",
        "\n",
        "def route_or_fallback(state: AgentState) -> str:\n",
        "    if state.get(\"last_tool_result\") == \"ERROR\" and state.get(\"retry_count\", 0) < MAX_RETRIES:\n",
        "        return \"route\"\n",
        "    if state.get(\"last_tool_result\") == \"ERROR\":\n",
        "        return \"fallback\"\n",
        "    return \"respond\"\n",
        "\n",
        "graph_fallback = StateGraph(AgentState)\n",
        "graph_fallback.add_node(\"route\", route_node_retry)\n",
        "graph_fallback.add_node(\"execute\", execute_node_with_fail)\n",
        "graph_fallback.add_node(\"respond\", respond_node)\n",
        "graph_fallback.add_node(\"fallback\", fallback_node)\n",
        "graph_fallback.set_entry_point(\"route\")\n",
        "graph_fallback.add_edge(\"route\", \"execute\")\n",
        "graph_fallback.add_conditional_edges(\"execute\", route_or_fallback, {\"route\": \"route\", \"respond\": \"respond\", \"fallback\": \"fallback\"})\n",
        "graph_fallback.add_edge(\"respond\", END)\n",
        "graph_fallback.add_edge(\"fallback\", END)\n",
        "app_fallback = graph_fallback.compile()\n",
        "\n",
        "r = app_fallback.invoke({\"messages\": [(\"user\", \"Weather?\")], \"last_tool_result\": \"\", \"retry_count\": 0})\n",
        "print(\"Final:\", r[\"messages\"][-1].content[:120])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: When all retries fail, the user sees the fallback message instead of a raw error. **Record**: That the graph always terminates (either respond or fallback).\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 4: Conditional routing (two tools) — **Optional (選做)**\n",
        "\n",
        "**Variable**: Two tools; route conditionally based on LLM output (which tool was chosen).  \n",
        "**Hypothesis**: The state object carries the routing decision; we can log or branch on it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Experiment 4 — Conditional routing (concept)\n",
        "\n",
        "# The LLM already chooses the tool via tool_calls; execute_node runs whichever tool was called.\n",
        "# \"Conditional routing\" here means: the graph branches only via should_retry / route_or_fallback.\n",
        "# For a second tool, we just ensure both tools are bound — the same graph works.\n",
        "# Run once with a docs query to see the other tool.\n",
        "r_docs = app_baseline.invoke({\"messages\": [(\"user\", \"Search the docs for API usage.\")], \"last_tool_result\": \"\", \"retry_count\": 0})\n",
        "print(\"Docs query ->\", r_docs[\"messages\"][-1].content[:100] if r_docs[\"messages\"] else \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: Same graph handles different tools; the LLM's tool_calls determine what execute runs. **Record**: For \"docs\" query, the agent should call search_docs.\n",
        "\n",
        "---\n",
        "\n",
        "### Experiment 5: Human-in-the-loop (simulated) — **Optional (選做)**\n",
        "\n",
        "**Variable**: Add an **escalate** node that \"pauses\" for simulated human input, then continues.  \n",
        "**Hypothesis**: Demonstrates an escape hatch when the agent cannot resolve the request.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Experiment 5 — Escalate (simulated human)\n",
        "\n",
        "def escalate_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Simulate human-in-the-loop: we inject a fixed 'human decision' and continue.\"\"\"\n",
        "    from langchain_core.messages import HumanMessage, AIMessage\n",
        "    # In production, this would wait for real user input\n",
        "    human_reply = \"Human: Use this response: 'The weather service is temporarily unavailable. Try again in 10 minutes.'\"\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [HumanMessage(content=human_reply)],\n",
        "        \"last_tool_result\": \"escalated\",\n",
        "        \"retry_count\": state.get(\"retry_count\", 0),\n",
        "    }\n",
        "\n",
        "def after_execute(state: AgentState) -> str:\n",
        "    if state.get(\"last_tool_result\") == \"ERROR\" and state.get(\"retry_count\", 0) >= MAX_RETRIES:\n",
        "        return \"escalate\"\n",
        "    if state.get(\"last_tool_result\") == \"ERROR\":\n",
        "        return \"route\"\n",
        "    return \"respond\"\n",
        "\n",
        "graph_escalate = StateGraph(AgentState)\n",
        "graph_escalate.add_node(\"route\", route_node_retry)\n",
        "graph_escalate.add_node(\"execute\", execute_node_with_fail)\n",
        "graph_escalate.add_node(\"respond\", respond_node)\n",
        "graph_escalate.add_node(\"escalate\", escalate_node)\n",
        "graph_escalate.set_entry_point(\"route\")\n",
        "graph_escalate.add_edge(\"route\", \"execute\")\n",
        "graph_escalate.add_conditional_edges(\"execute\", after_execute, {\"route\": \"route\", \"respond\": \"respond\", \"escalate\": \"escalate\"})\n",
        "graph_escalate.add_edge(\"escalate\", \"respond\")  # After human input, format and end\n",
        "graph_escalate.add_edge(\"respond\", END)\n",
        "app_escalate = graph_escalate.compile()\n",
        "\n",
        "r = app_escalate.invoke({\"messages\": [(\"user\", \"Weather?\")], \"last_tool_result\": \"\", \"retry_count\": 0})\n",
        "print(\"With escalation path:\", r[\"messages\"][-1].content[:150] if r[\"messages\"] else \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: When retries are exhausted, the graph goes to escalate; the simulated human reply is then passed to respond. **Record**: That the final answer can reflect the \"human\" message.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Maintenance Connection: Reading and Evolving EOP Agent Graphs\n",
        "\n",
        "### Reading a LangGraph definition\n",
        "\n",
        "- **Nodes**: Identify each node (route, execute, respond, fallback, escalate). Each is a function that takes state and returns state updates.\n",
        "- **Edges**: Conditional edges implement branching; fixed edges implement linear flow. Check that every cycle has a bounded exit (max_retries, success).\n",
        "\n",
        "### Common failure patterns\n",
        "\n",
        "| Pattern | Symptom | Fix |\n",
        "|--------|---------|-----|\n",
        "| Infinite retry | Workflow never ends | Add max_retries and route to fallback or escalate |\n",
        "| Silent failure | No error, no answer | Add fallback node and ensure errors set last_tool_result (or similar) |\n",
        "| State corruption | Wrong data passed between nodes | Validate state shape; use TypedDict and clear keys |\n",
        "\n",
        "### Adding a new tool or node\n",
        "\n",
        "- Add a new tool to the list bound to the LLM; add a new node if the action is not “call a tool” (e.g. a validation node). Connect it with an edge from the appropriate predecessor and to the appropriate successor. Ensure state keys are consistent.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Summary and Next Steps\n",
        "\n",
        "### Four takeaways\n",
        "\n",
        "1. **Agents are graphs.** Nodes are actions; edges are transitions; state flows through the graph.\n",
        "2. **Cycles need bounds.** Use max_retries or success conditions so the graph always terminates.\n",
        "3. **Fallbacks prevent silent failures.** When retries are exhausted or a node fails, route to a fallback or human-in-the-loop node.\n",
        "4. **State flows through edges.** Keep state shape consistent (e.g. AgentState) so every node can read and write the same keys.\n",
        "\n",
        "### Capstone idea\n",
        "\n",
        "Combine Labs 1–4: a multi-tool agent with structured schemas (Lab 2), persistent memory (Lab 3), and graph-based orchestration with retry and fallback (Lab 4).\n",
        "\n",
        "### Checkpoint: Self-check before Lab 5 (Foundation 1–4)\n",
        "\n",
        "Before moving to the domain labs (Lab 5–6), confirm you can:\n",
        "\n",
        "| Skill | Labs | Self-check question |\n",
        "|-------|------|----------------------|\n",
        "| Prompt → tool selection | 1 | Can you debug wrong tool choice using prompt structure or temperature? |\n",
        "| Tool schema & validation | 2 | Can you add a tool with Pydantic and handle invalid args? |\n",
        "| Multi-turn state & history | 3 | Can you maintain messages and optional state across turns? |\n",
        "| Graph: nodes, edges, state | 4 | Can you read a LangGraph and say what each node does and when retry/fallback run? |\n",
        "\n",
        "If yes, you’re ready to plug domain logic (ECF extraction, disclosure advice) in as tools or nodes in Lab 5–6.\n",
        "\n",
        "### What's next\n",
        "\n",
        "**Lab 5 — Evidence Chain Extraction**: Domain layer. Given a messy research repo, identify ECF's seven artifacts and suggest restructuring.\n",
        "\n",
        "---\n",
        "\n",
        "*End of Lab 4. Proceed to Lab 5 when ready.*\n"
      ]
    }
  ]
}