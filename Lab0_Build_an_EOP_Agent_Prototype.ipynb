{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Lab0_Build_an_EOP_Agent_Prototype.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 0: Build a Minimal EOP Agent Prototype — Step by Step\n",
        "\n",
        "**Series**: Agentic Engineering Crash Course (EOP focus)\n",
        "**Goal**: Assemble the simplest agent that understands “evidence-oriented” actions and chooses a tool to help researchers annotate or link artifacts.\n",
        "**Prerequisites**: Python 3.10+, OpenAI API key (or NVIDIA NIM).\n",
        "**Time**: ~30–40 min.\n",
        "\n",
        "---\n",
        "\n",
        "## What Is This Tutorial About? (Plain English)\n",
        "\n",
        "Imagine a research scientist writes code to run an experiment — they produce input data, run scripts, and generate figures for a paper. **Evidence-Oriented Programming (EOP)** is a way of organizing that code so that every figure or claim in the paper can be traced back to the exact data and code that produced it.\n",
        "\n",
        "This tutorial teaches you to build an **AI agent** that helps researchers do that tracing automatically. The agent reads what a researcher is asking (e.g. “tag this file as input data”) and picks the right action to take.\n",
        "\n",
        "**You don't need any AI or machine learning background.** If you know Python, you can follow along. Every AI concept is explained as you go. Unfamiliar terms are defined in [Glossary](Glossary.md).\n",
        "\n",
        "---\n",
        "\n",
        "## What You Will Accomplish (Step by Step)\n",
        "\n",
        "By the end of this lab you will have written a Python program that:\n",
        "\n",
        "1. Connects to an AI model (via API)\n",
        "2. Reads a researcher's request\n",
        "3. Picks one of two actions: “annotate an artifact” or “link to a claim”\n",
        "4. Runs that action and returns a result\n",
        "\n",
        "That's it. No magic — just a prompt, an API call, a parser, and a function.\n",
        "\n",
        "---\n",
        "\n",
        "## What You Will Build\n",
        "\n",
        "By the end of this lab you will have a **single-turn EOP agent** that:\n",
        "\n",
        "1. Reads a user message (e.g. “Tag this file as input data” or “Link Figure 2 to the main claim”).\n",
        "2. Chooses one of two **EOP tools**: `annotate_artifact` or `link_to_claim`.\n",
        "3. Executes the chosen tool and returns a short result.\n",
        "\n",
        "No frameworks (LangChain/LangGraph) — just prompt, LLM call, parse, and execute. This matches the idea from the EOP paper: *AI agents might assist researchers in identifying and annotating evidentiary artifacts during software development*.\n",
        "\n",
        "---\n",
        "\n",
        "## How to Use This Tutorial\n",
        "\n",
        "- **Notebook**: Open `Lab0_Build_an_EOP_Agent_Prototype.ipynb` in Jupyter or Google Colab and run cells in order.\n",
        "- **Markdown**: Alternatively, copy sections from this `.md` file into a new notebook or a `.py` file and run top to bottom.\n",
        "\n",
        "For terms (prompt, tool call, LLM), see [Glossary](Glossary.md).\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Setup\n",
        "\n",
        "> **Getting an API key**\n",
        ">\n",
        "> You need an API key to send requests to an AI model. Two options:\n",
        ">\n",
        "> - **OpenAI** (recommended for beginners): Sign up at [platform.openai.com](https://platform.openai.com), add a small credit ($5 is enough for all 6 labs), and copy your API key from the dashboard.\n",
        "> - **NVIDIA NIM** (free tier available for NVIDIA employees/researchers): Use your NIM API key and set `USE_NIM=1` in your environment.\n",
        ">\n",
        "> Keep your API key secret — never paste it directly into a shared notebook or commit it to git.\n",
        "\n",
        "Install the client and load your API key. The same setup pattern is used across all labs in this series.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Install\n",
        "!pip install -q openai\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Imports and API key\n",
        "import os\n",
        "import re\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "use_nim = os.environ.get(\"USE_NIM\", \"\").lower() in (\"1\", \"true\", \"yes\") or \"NIM_API_KEY\" in os.environ\n",
        "if use_nim:\n",
        "    if \"NIM_API_KEY\" not in os.environ:\n",
        "        os.environ[\"NIM_API_KEY\"] = getpass(\"Enter your NVIDIA API key (NIM): \")\n",
        "    client = OpenAI(base_url=\"https://integrate.api.nvidia.com/v1\", api_key=os.environ[\"NIM_API_KEY\"])\n",
        "    MODEL = os.environ.get(\"NIM_MODEL\", \"nvidia/llama-3.3-nemotron-super-49b-v1.5\")\n",
        "else:\n",
        "    if \"OPENAI_API_KEY\" not in os.environ:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "    client = OpenAI()\n",
        "    MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "print(f\"Using model: {MODEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Define EOP Tools (Concept Only)\n",
        "\n",
        "We define two tools that match the EOP idea of *identifying and linking evidence*:\n",
        "\n",
        "| Tool | When to use |\n",
        "|------|------------------|\n",
        "| `annotate_artifact` | User wants to tag a file, dataset, or figure/table as part of the evidence chain (e.g. input data, output data, visual claim). |\n",
        "| `link_to_claim`     | User wants to link an artifact or process to a scientific claim. |\n",
        "\n",
        "For this prototype, each tool is a Python function that returns a short message. No real I/O yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: EOP tool definitions (implementations)\n",
        "\n",
        "EOP_TOOLS = {\n",
        "    \"annotate_artifact\": \"Tag a file or data artifact as part of the evidence chain (e.g. input_data, output_data, visual_claim). Use when the user mentions a file, dataset, or figure/table they want to annotate.\",\n",
        "    \"link_to_claim\": \"Link an artifact or process to a scientific claim. Use when the user wants to associate evidence with a claim or figure/table with a claim.\",\n",
        "}\n",
        "\n",
        "\n",
        "def execute_annotate_artifact(artifact_name: str = \"\") -> str:\n",
        "    \"\"\"Placeholder: in a full implementation, this would update metadata or a manifest.\"\"\"\n",
        "    return f\"[EOP] Annotated artifact: {artifact_name or '(unspecified)'} — recorded in evidence chain.\"\n",
        "\n",
        "\n",
        "def execute_link_to_claim(artifact_name: str = \"\", claim_text: str = \"\") -> str:\n",
        "    \"\"\"Placeholder: in a full implementation, this would store the artifact–claim link.\"\"\"\n",
        "    return f\"[EOP] Linked '{artifact_name or '(artifact)'}' to claim: '{claim_text or '(claim)'}'.\"\n",
        "\n",
        "\n",
        "def run_tool(tool_name: str, **kwargs) -> str:\n",
        "    \"\"\"Execute the named EOP tool and return a result string.\"\"\"\n",
        "    if tool_name == \"annotate_artifact\":\n",
        "        return execute_annotate_artifact(artifact_name=kwargs.get(\"artifact_name\", \"\"))\n",
        "    if tool_name == \"link_to_claim\":\n",
        "        return execute_link_to_claim(\n",
        "            artifact_name=kwargs.get(\"artifact_name\", \"\"),\n",
        "            claim_text=kwargs.get(\"claim_text\", \"\"),\n",
        "        )\n",
        "    return f\"[EOP] Unknown tool: {tool_name}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Check**: You now have a tool registry (`EOP_TOOLS`) and an executor (`run_tool`). The agent’s job is to *choose* `tool_name`; we will parse it from the LLM output in the next steps.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3: Build the Prompt and Ask the LLM for a Tool Choice\n",
        "\n",
        "The agent prompt has two parts: (1) system message = “you have these tools, reply with TOOL: <name>”; (2) user message = the researcher’s request. We send them to the LLM and get back one line like `TOOL: annotate_artifact`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Prompt builder and tool-choice call\n",
        "\n",
        "def build_system_prompt(tools: dict) -> str:\n",
        "    \"\"\"Build the system message that lists EOP tools and the reply format.\"\"\"\n",
        "    lines = [\n",
        "        \"You are an EOP (Evidence-Oriented Programming) assistant. You help researchers annotate artifacts and link them to scientific claims.\",\n",
        "        \"\",\n",
        "        \"You have the following tools:\",\n",
        "    ]\n",
        "    for i, (name, desc) in enumerate(tools.items(), 1):\n",
        "        lines.append(f\"  {i}. {name} — {desc}\")\n",
        "    lines.extend([\n",
        "        \"\",\n",
        "        \"Given the user's message, choose exactly one tool to invoke.\",\n",
        "        \"Reply with exactly one line in this format:\",\n",
        "        \"TOOL: <tool_name>\",\n",
        "        \"Do not include any other text.\",\n",
        "    ])\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def parse_tool_choice(response_text: str):\n",
        "    \"\"\"Extract tool name from a line like 'TOOL: annotate_artifact'.\"\"\"\n",
        "    match = re.search(r\"TOOL:\\s*(\\S+)\", response_text.strip(), re.IGNORECASE)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "\n",
        "def ask_agent_for_tool(user_message: str, tools: dict, temperature: float = 0.0):\n",
        "    \"\"\"Send user message to the LLM; return raw response and parsed tool name.\"\"\"\n",
        "    system = build_system_prompt(tools)\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        temperature=temperature,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ],\n",
        "        max_tokens=50,\n",
        "    )\n",
        "    text = (response.choices[0].message.content or \"\").strip()\n",
        "    tool = parse_tool_choice(text)\n",
        "    return {\"raw\": text, \"tool\": tool}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: Same idea as Lab 1 — prompt structure and format (e.g. “TOOL: …”) determine whether the model’s answer is easy to parse and correct.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 4: Wire Tool Choice to Execution (One Turn)\n",
        "\n",
        "Combine “ask LLM” and “run tool” into a single function. For the prototype we do not parse arguments from the LLM; we pass the raw `user_message` as a simple context string so the placeholder tools have something to show.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Single-turn EOP agent\n",
        "\n",
        "def run_eop_agent(user_message: str, tools: dict = None, temperature: float = 0.0):\n",
        "    \"\"\"\n",
        "    One turn: user message -> LLM chooses tool -> we execute tool -> return result.\n",
        "    \"\"\"\n",
        "    if tools is None:\n",
        "        tools = EOP_TOOLS\n",
        "\n",
        "    step1 = ask_agent_for_tool(user_message, tools, temperature=temperature)\n",
        "    chosen = step1[\"tool\"]\n",
        "\n",
        "    if not chosen or chosen not in tools:\n",
        "        return {\n",
        "            \"user_message\": user_message,\n",
        "            \"raw_response\": step1[\"raw\"],\n",
        "            \"chosen_tool\": chosen,\n",
        "            \"tool_result\": None,\n",
        "            \"error\": \"No valid tool parsed or tool not in list.\",\n",
        "        }\n",
        "\n",
        "    # Optional: later you could parse artifact_name / claim_text from user_message or from LLM\n",
        "    tool_result = run_tool(chosen, artifact_name=user_message[:80], claim_text=\"\")\n",
        "\n",
        "    return {\n",
        "        \"user_message\": user_message,\n",
        "        \"raw_response\": step1[\"raw\"],\n",
        "        \"chosen_tool\": chosen,\n",
        "        \"tool_result\": tool_result,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5: Try Your EOP Agent\n",
        "\n",
        "Run a few example user messages and inspect the chosen tool and the placeholder result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Run examples\n",
        "\n",
        "examples = [\n",
        "    \"Tag the file data/measurements.csv as input data for the experiment.\",\n",
        "    \"Link Figure 2 to the main claim about the correlation.\",\n",
        "    \"I want to annotate the trained model checkpoint as output data.\",\n",
        "]\n",
        "\n",
        "for msg in examples:\n",
        "    out = run_eop_agent(msg, temperature=0.0)\n",
        "    print(\"User:\", out[\"user_message\"])\n",
        "    print(\"LLM said:\", out[\"raw_response\"])\n",
        "    print(\"Chosen tool:\", out[\"chosen_tool\"])\n",
        "    print(\"Tool result:\", out[\"tool_result\"])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Record**:\n",
        "\n",
        "- For “Tag the file …” / “annotate …” you should usually see `annotate_artifact`.\n",
        "- For “Link Figure 2 to the main claim” you should usually see `link_to_claim`.\n",
        "- If something different happens, note it — that’s the kind of behavior Lab 1 teaches you to fix with prompt structure and temperature.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 6: Optional — “No Tool” and Format Drift\n",
        "\n",
        "Sometimes the user might ask something that doesn’t clearly map to a tool (e.g. “What is EOP?”). The model might then reply with text that doesn’t match `TOOL: <name>`, and `parse_tool_choice` returns `None`. Our agent already handles that by returning `chosen_tool: None` and `error: \"No valid tool parsed...\"`. Try it:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Cell: Optional — query that may not map to a tool\n",
        "\n",
        "out = run_eop_agent(\"What is Evidence-Oriented Programming?\", temperature=0.0)\n",
        "print(\"Chosen tool:\", out[\"chosen_tool\"])\n",
        "print(\"Tool result:\", out[\"tool_result\"])\n",
        "print(\"Error:\", out.get(\"error\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**: When the answer is not in the expected format, the agent “fails gracefully” (no crash, but no tool run). Improving this (e.g. a “no_tool” or “answer_directly” option) is a natural next step.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary and Next Steps\n",
        "\n",
        "You built a minimal EOP agent that:\n",
        "\n",
        "1. **Setup**: Connects to an LLM (OpenAI or NIM).\n",
        "2. **Tools**: Defines two EOP-themed tools and executes them via `run_tool`.\n",
        "3. **Prompt**: Builds a system message that lists tools and asks for `TOOL: <name>`.\n",
        "4. **Parse**: Extracts the tool name from the model output.\n",
        "5. **Run**: Calls `run_eop_agent(user_message)` → LLM chooses tool → execute → return result.\n",
        "\n",
        "**Takeaways**:\n",
        "\n",
        "- The agent is a loop: *user message → prompt (system + user) → LLM → parse tool → execute tool*. This is the same anatomy you see in Lab 1; here we added execution.\n",
        "- EOP tools are just functions; the “evidence chain” is only simulated (placeholder messages). A real implementation would write to a manifest or database.\n",
        "- Prompt structure and reply format matter: if you change the wording or the “TOOL: …” convention, parsing can break (format drift).\n",
        "\n",
        "**Next**:\n",
        "\n",
        "- **Lab 1** — Understand why the model sometimes picks the wrong tool (order, temperature, vague prompts) and how to debug.\n",
        "- **Lab 2** — Define tools with a proper schema (e.g. Pydantic) so the model can return *arguments* (e.g. `artifact_name`, `claim_text`) and you can pass them into `run_tool` instead of the raw message.\n",
        "\n",
        "---\n",
        "\n",
        "*For the full series, see Lab 1–6 in the Agentic Engineering Crash Course and the EOP/ECF materials.*\n"
      ]
    }
  ]
}